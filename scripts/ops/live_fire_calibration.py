#!/usr/bin/env python3
"""
PHASE 2.7: LIVE FIRE RE-CALIBRATION (ALBRIGHT ONLY)

Mission: Validate V2.0-LITE "18-Month Advantage" hypothesis with real API data.
Authorization: CSO Authorization for Live API Spend
Mode: FORCED LIVE EXECUTION
    - Real ProPublica API: Live financial data retrieval
    - Real Perplexity Recon: Live API calls
    - Real Claude Synthesis: Live API calls
    - enable_v2_lite=True: Full V2-LITE pipeline (no fallback)

Target Cohort:
1. Albright College (23-1352650) - Expected: Critical (+45 delta from V1)

Execution Date: February 3, 2026
NOTE: Forced LIVE execution. No hybrid/mocked fallback. Exceptions will surface.
"""

import sys
import os
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
from dotenv import load_dotenv

# =============================================================================
# ENVIRONMENT SETUP & API KEY VERIFICATION
# =============================================================================

# Load environment variables from .env
load_dotenv()

# Verify API keys exist
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not ANTHROPIC_API_KEY:
    print("[ERROR] ANTHROPIC_API_KEY not found in .env")
    print("        Please set ANTHROPIC_API_KEY in .env and retry.")
    sys.exit(1)

if not PERPLEXITY_API_KEY:
    print("[ERROR] PERPLEXITY_API_KEY not found in .env")
    print("        Please set PERPLEXITY_API_KEY in .env and retry.")
    sys.exit(1)

print("[âœ“] Environment Verification")
print("[âœ“] ANTHROPIC_API_KEY loaded (live Claude API enabled)")
print("[âœ“] PERPLEXITY_API_KEY loaded (live Perplexity API enabled)")
print()

# =============================================================================
# PATH CONFIGURATION
# =============================================================================

PROJECT_ROOT = Path(__file__).parent.parent.parent
ANALYST_ROOT = PROJECT_ROOT / "agents" / "analyst"
RESULTS_DIR = PROJECT_ROOT / "data" / "live_fire_results"

# Add to sys.path for imports
for path in (str(PROJECT_ROOT), str(ANALYST_ROOT)):
    if path not in sys.path:
        sys.path.insert(0, path)

# Import analyst generate_dossier
from analyst import generate_dossier

# =============================================================================
# HARDCODED 5-UNIVERSITY LIVE FIRE COHORT
# =============================================================================

LIVE_FIRE_COHORT = [
    {
        "name": "Albright College",
        "ein": "23-1352650",
        "expected": "Critical",
        "expected_delta": "+45"
    }
]

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def slugify(name: str) -> str:
    """Convert institution name to filesystem-safe slug."""
    slug = name.lower()
    slug = re.sub(r'[^a-z0-9]+', '_', slug)
    slug = re.sub(r'^_+|_+$', '', slug)
    return slug[:50]

def load_profile_json(json_path: str) -> Dict[str, Any]:
    """Load JSON profile from generated dossier."""
    try:
        with open(json_path, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"[ERROR] Failed to load {json_path}: {e}")
        return {}

def extract_key_signals(profile: Dict[str, Any]) -> List[str]:
    """Extract key V2 signals from profile."""
    signals = []
    v2_signals = profile.get("v2_signals", [])
    
    for signal in v2_signals[:3]:  # Top 3 signals
        if isinstance(signal, dict):
            # Try different signal formats
            if "finding" in signal:
                signals.append(signal.get("finding", "Unknown signal"))
            elif "type" in signal:
                signals.append(f"{signal.get('type', 'Signal')}")
            else:
                signals.append(str(signal)[:60])
    
    return signals

def extract_profile_metrics(profile: Dict[str, Any]) -> Dict[str, Any]:
    """Extract key metrics from V2 profile."""
    metrics = {
        "name": profile.get("institution", {}).get("name", "UNKNOWN"),
        "ein": profile.get("institution", {}).get("ein", "N/A"),
        "v1_base_score": profile.get("institution", {}).get("risk_score", 0),
        "v2_composite_score": profile.get("composite_score", 0),
        "urgency_flag": profile.get("urgency_flag", "UNKNOWN"),
        "has_v2_signals": "v2_signals" in profile,
        "v2_signal_count": len(profile.get("v2_signals", [])),
        "api_calls_made": profile.get("meta", {}).get("api_calls_made", 0),
        "v2_signals": extract_key_signals(profile),
    }
    
    # Calculate delta
    v1_score = profile.get("institution", {}).get("risk_score", 0)
    v2_score = profile.get("composite_score", 0)
    metrics["delta"] = v2_score - v1_score if v1_score > 0 else 0
    
    return metrics

# =============================================================================
# MAIN LIVE FIRE EXECUTION
# =============================================================================

def execute_live_fire_calibration():
    """Execute live API calls for 5-university cohort."""
    
    start_time = datetime.now()
    log_lines = []
    results = []
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HEADER
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    log_lines.append("=" * 90)
    log_lines.append("PHASE 2.7: LIVE FIRE RE-CALIBRATION (ALBRIGHT ONLY)")
    log_lines.append("=" * 90)
    log_lines.append(f"Execution Start: {start_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
    log_lines.append(f"Cohort Size: {len(LIVE_FIRE_COHORT)} universities")
    log_lines.append(f"Pipeline: V2.0-LITE FORCED LIVE EXECUTION")
    log_lines.append(f"  - ProPublica: LIVE financial data retrieval")
    log_lines.append(f"  - Perplexity: LIVE reconnaissance")
    log_lines.append(f"  - Claude: LIVE synthesis")
    log_lines.append(f"  - V2 Scoring: LIVE signals + V1 baseline")
    log_lines.append(f"Authorization: CSO Authorization for Live API Spend")
    log_lines.append(f"Mode: LIVE (No fallback - exceptions bubble up)")
    log_lines.append("")
    
    print("\n" + log_lines[0])
    print(log_lines[1])
    print(log_lines[0])
    print(f"ðŸ”´ LIVE EXECUTION INITIATED")
    print(f"   ProPublica API: LIVE")
    print(f"   Perplexity API: LIVE")
    print(f"   Claude API: LIVE")
    print()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # PROCESS EACH UNIVERSITY (LIVE API)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    total_api_calls = 0
    success_count = 0
    total_cost = 0.0
    
    cohort_size = len(LIVE_FIRE_COHORT)
    for idx, target in enumerate(LIVE_FIRE_COHORT, 1):
        name = target["name"]
        ein = target["ein"]
        slug = slugify(name)
        expected = target["expected"]
        expected_delta = target["expected_delta"]
        
        log_lines.append(f"[{idx}/{cohort_size}] Processing: {name} ({ein})")
        print(f"\n[{idx}/{cohort_size}] ðŸ”´ EXECUTION: {name}")
        print(f"      EIN: {ein}")
        print(f"      Expected: {expected} (Î” {expected_delta})")
        print(f"      Status: Fetching ProPublica data...")
        
        # Generate dossier with enable_v2_lite=True
        # Exceptions must bubble up (no graceful fallback)
        result = generate_dossier(
            target_name=name,
            ein=ein,
            output_dir=str(RESULTS_DIR),
            enable_v2_lite=True  # Enables V2-LITE pipeline
        )
        
        # Load the generated JSON profile
        json_path = result.get("json")
        elapsed = result.get("elapsed_seconds", 0)
        
        if json_path and Path(json_path).exists():
            profile = load_profile_json(json_path)
            metrics = extract_profile_metrics(profile)
            
            # Save to live results directory with slug name
            output_json = RESULTS_DIR / f"{slug}_live_v2_profile.json"
            with open(output_json, 'w') as f:
                json.dump(profile, f, indent=2)
            
            # Track results
            results.append({
                "name": name,
                "ein": ein,
                "slug": slug,
                "metrics": metrics,
                "elapsed_seconds": elapsed,
                "status": "SUCCESS"
            })
            
            # Log metrics
            v1_score = metrics.get("v1_base_score", 0)
            v2_score = metrics.get("v2_composite_score", 0)
            delta = metrics.get("delta", 0)
            urgency = metrics.get("urgency_flag", "UNKNOWN")
            api_calls = metrics.get("api_calls_made", 0)
            v2_signal_count = metrics.get("v2_signal_count", 0)
            
            log_lines.append(f"  âœ“ V1 Score: {v1_score:.0f} â†’ V2 Score: {v2_score:.0f} (Î” {delta:+.0f})")
            log_lines.append(f"  âœ“ Urgency: {urgency} | V2 Signals: {v2_signal_count} | API Calls: {api_calls}")
            log_lines.append(f"  âœ“ Processing Time: {elapsed:.2f}s")
            log_lines.append(f"  âœ“ Saved: {output_json.name}")
            
            # Print to terminal
            print(f"      âœ“ V1 Score: {v1_score:.0f} â†’ V2 Score: {v2_score:.0f} (Î” {delta:+.0f})")
            print(f"      âœ“ Urgency: {urgency}")
            print(f"      âœ“ V2 Signals Found: {v2_signal_count}")
            
            if v2_signal_count > 0:
                signals = metrics.get("v2_signals", [])
                for sig_idx, sig in enumerate(signals[:2], 1):
                    print(f"        - Signal {sig_idx}: {sig[:70]}")
            
            print(f"      âœ“ API Calls Made: {api_calls}")
            print(f"      âœ“ Processing Time: {elapsed:.2f}s")
            
            total_api_calls += api_calls
            success_count += 1
            
        else:
            raise FileNotFoundError(f"JSON profile not found at {json_path}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # GENERATE SUMMARY TABLE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n" + "=" * 90)
    print("LIVE FIRE RESULTS SUMMARY")
    print("=" * 90)
    print("\n| Institution | V2 Score | Urgency | Key Signal | Status |")
    print("|---|---|---|---|---|")
    
    for result in sorted(
        [r for r in results if r["status"] == "SUCCESS"],
        key=lambda x: x["metrics"].get("v2_composite_score", 0),
        reverse=True
    ):
        metrics = result["metrics"]
        name = result["name"][:35]
        v2_score = metrics.get("v2_composite_score", 0)
        urgency = metrics.get("urgency_flag", "UNKNOWN")
        signals = metrics.get("v2_signals", [])
        key_signal = signals[0][:50] if signals else "No signals"
        
        print(f"| {name:<35} | {v2_score:>6.0f} | {urgency:<12} | {key_signal:<50} | âœ“ |")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # SAVE EXECUTION LOG
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    log_lines.append("")
    log_lines.append("=" * 90)
    log_lines.append(f"Execution Complete: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
    log_lines.append(f"Success Rate: {success_count}/{len(LIVE_FIRE_COHORT)} ({100*success_count//len(LIVE_FIRE_COHORT)}%)")
    log_lines.append(f"Total API Calls Made: {total_api_calls}")
    log_lines.append("=" * 90)
    
    log_path = RESULTS_DIR / "LIVE_FIRE_EXECUTION_LOG.txt"
    with open(log_path, 'w') as f:
        f.write("\n".join(log_lines))
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # FINAL SUMMARY
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n" + "=" * 90)
    print("LIVE FIRE CALIBRATION COMPLETE")
    print("=" * 90)
    print(f"âœ“ Processed: {success_count}/{len(LIVE_FIRE_COHORT)} universities")
    print(f"âœ“ Live API calls completed: {total_api_calls}")
    print(f"âœ“ Profiles saved: data/live_fire_results/")
    print(f"âœ“ Execution log: LIVE_FIRE_EXECUTION_LOG.txt")
    print("=" * 90)
    
    return results, total_api_calls


if __name__ == "__main__":
    results, total_api_calls = execute_live_fire_calibration()
